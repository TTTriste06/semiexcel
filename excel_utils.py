import pandas as pd
import streamlit as st
import re
from openpyxl import Workbook
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment, Font
from openpyxl.styles import PatternFill
from openpyxl.worksheet.table import Table, TableStyleInfo
from openpyxl.cell.cell import MergedCell


def standardize(val):
    """
    å°†è¾“å…¥æ ‡å‡†åŒ–ä¸ºå¯æ¯”è¾ƒçš„å­—ç¬¦ä¸²ï¼š
    - è½¬å­—ç¬¦ä¸²
    - å»é™¤é¦–å°¾ç©ºæ ¼
    - å»é™¤å•å¼•å·/åŒå¼•å·ï¼ˆè‹±æ–‡å’Œä¸­æ–‡ï¼‰
    - ç»Ÿä¸€åŠè§’/å…¨è§’ç©ºæ ¼
    """
    if val is None:
        return ''
    
    val = str(val).strip()
    
    # å»æ‰åŒ…è£¹çš„å¼•å·ï¼ˆåŒ…æ‹¬ä¸­è‹±æ–‡å•å¼•å·å’ŒåŒå¼•å·ï¼‰
    val = val.strip('\'"â€œâ€â€˜â€™')  # å«ä¸­æ–‡å¼•å·
    
    # æ›¿æ¢å…¨è§’ç©ºæ ¼ä¸ºåŠè§’ç©ºæ ¼
    val = val.replace('\u3000', ' ')

    return val







def clean_df(df):
    df = df.fillna("")  # å¤„ç†çœŸæ­£çš„ NaN/None
    df = df.applymap(lambda x: "" if str(x).strip().lower() == "nan" else str(x).strip() if isinstance(x, str) else x)
    return df


def clear_nan_cells(ws):
    """
    éå†æŒ‡å®šå·¥ä½œè¡¨ï¼Œå°† 'nan'ã€'NaN'ã€None å’Œç©ºå­—ç¬¦ä¸²ç»Ÿä¸€æ¸…ç©ºã€‚
    """
    for row in ws.iter_rows():
        for cell in row:
            if isinstance(cell, MergedCell):
                continue
            val = cell.value
            if val is None or (isinstance(val, float) and pd.isna(val)) or str(val).strip().lower() == "nan":
                cell.value = ""


def clean_key_fields(df, field_map):
    for col in [field_map["è§„æ ¼"], field_map["å“å"], field_map["æ™¶åœ†å“å"]]:
        df[col] = (
            df[col]
            .astype(str)
            .str.replace(r"\s+", "", regex=True)  # ç§»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦ï¼ˆå«ç©ºæ ¼ã€å…¨è§’ç©ºæ ¼ã€Tabã€æ¢è¡Œï¼‰
            .str.replace(r"[\u200b\u200e\u200f]", "", regex=True)  # æ¸…é™¤ä¸å¯è§å­—ç¬¦
            .str.strip()
        )
    return df










def adjust_column_width(writer, sheet_name, df):
    """
    è‡ªåŠ¨è°ƒæ•´ Excel å·¥ä½œè¡¨ä¸­å„åˆ—çš„å®½åº¦ä»¥é€‚åº”å†…å®¹é•¿åº¦ã€‚

    å‚æ•°:
    - writer: pandas çš„ ExcelWriter å¯¹è±¡
    - sheet_name: è¦è°ƒæ•´çš„å·¥ä½œè¡¨åç§°
    - df: å¯¹åº”å†™å…¥å·¥ä½œè¡¨çš„ DataFrame æ•°æ®
    """
    worksheet = writer.sheets[sheet_name]
    for idx, col in enumerate(df.columns, 1):
        # è·å–è¯¥åˆ—ä¸­æ‰€æœ‰å­—ç¬¦ä¸²é•¿åº¦çš„æœ€å¤§å€¼
        max_content_len = df[col].astype(str).str.len().max()
        header_len = len(str(col))
        column_width = max(max_content_len, header_len) * 1.2 + 8
        worksheet.column_dimensions[get_column_letter(idx)].width = min(column_width, 50)

def adjust_column_width_ws(ws):
    """
    æ ¹æ®æ¯ä¸ªå•å…ƒæ ¼å†…å®¹é•¿åº¦ï¼Œè‡ªåŠ¨è°ƒæ•´ openpyxl Worksheet çš„åˆ—å®½ã€‚
    """
    column_widths = {}
    for row in ws.iter_rows(values_only=True):
        for i, cell in enumerate(row):
            if cell is not None:
                width = len(str(cell))
                if i in column_widths:
                    column_widths[i] = max(column_widths[i], width)
                else:
                    column_widths[i] = width

    for i, width in column_widths.items():
        col_letter = get_column_letter(i + 1)
        ws.column_dimensions[col_letter].width = width + 88  # å¯è°ƒèŠ‚ +2 ç¼“å†²








def merge_header_for_summary(ws, df, label_ranges):
    """
    ç»™æŒ‡å®šæ±‡æ€»åˆ—æ·»åŠ é¡¶éƒ¨åˆå¹¶è¡Œæ ‡é¢˜ï¼ˆå¦‚â€œå®‰å…¨åº“å­˜â€â€œæœªäº¤è®¢å•â€ï¼‰

    å‚æ•°:
    - ws: openpyxl worksheet
    - df: summary DataFrame
    - label_ranges: dictï¼Œé”®æ˜¯æ ‡é¢˜æ–‡å­—ï¼Œå€¼æ˜¯åˆ—åèŒƒå›´å…ƒç»„ï¼Œå¦‚ï¼š
        {
            "å®‰å…¨åº“å­˜": (" InvWaf", " InvPart"),
            "æœªäº¤è®¢å•": ("æ€»æœªäº¤è®¢å•", "æœªäº¤è®¢å•æ•°é‡_2025-08")
        }
    """

    # æ’å…¥ä¸€è¡Œä½œä¸ºæ–°è¡¨å¤´ï¼ˆåŸè¡¨å¤´å¾€ä¸‹æŒªï¼‰
    ws.insert_rows(1)
    header_row = list(df.columns)

    for label, (start_col_name, end_col_name) in label_ranges.items():
        if start_col_name not in header_row or end_col_name not in header_row:
            continue

        start_idx = header_row.index(start_col_name) + 1  # Excel index starts from 1
        end_idx = header_row.index(end_col_name) + 1

        col_letter_start = get_column_letter(start_idx)
        col_letter_end = get_column_letter(end_idx)

        merge_range = f"{col_letter_start}1:{col_letter_end}1"
        ws.merge_cells(merge_range)
        cell = ws[f"{col_letter_start}1"]
        cell.value = label
        cell.alignment = Alignment(horizontal="center", vertical="center")
        cell.font = Font(bold=True)

def get_column_index_by_name(ws, target_name: str, header_row: int = 1):
    """
    ä» Excel sheet çš„æŒ‡å®šè¡¨å¤´è¡Œä¸­æŸ¥æ‰¾åˆ—åå¯¹åº”çš„åˆ—å·ï¼ˆ1-basedï¼‰
    """
    for cell in ws[header_row]:
        if str(cell.value).strip() == target_name:
            return cell.column
    return None


def merge_duplicate_product_names(summary_df: pd.DataFrame) -> pd.DataFrame:
    """
    åˆå¹¶ 'æ±‡æ€»' è¡¨ä¸­é‡å¤çš„å“åï¼ˆæŒ‰å“ååˆ†ç»„ï¼‰ï¼Œé€‰ç”¨ç¬¬ä¸€è¡Œçš„ æ™¶åœ†å“å å’Œ è§„æ ¼ï¼Œåˆå¹¶å…¶æ•°å€¼åˆ—ã€‚
    """
    # ç¡®ä¿å¿…è¦åˆ—å­˜åœ¨
    required_cols = ["æ™¶åœ†å“å", "è§„æ ¼", "å“å"]
    for col in required_cols:
        if col not in summary_df.columns:
            raise ValueError(f"ç¼ºå°‘å¿…è¦åˆ—ï¼š{col}")

    # è¯†åˆ«æ•°å€¼åˆ—ï¼ˆæ’é™¤ä¸»é”®åˆ—ï¼‰
    value_cols = [col for col in summary_df.columns if col not in required_cols]

    # åˆ†ç»„åˆå¹¶æ•°å€¼åˆ—
    grouped = summary_df.groupby("å“å", sort=False)

    merged_rows = []

    for name, group in grouped:
        if len(group) == 1:
            merged_rows.append(group.iloc[0])
        else:
            # å–ç¬¬ä¸€è¡Œçš„ æ™¶åœ†å“å å’Œ è§„æ ¼
            base_row = group.iloc[0][required_cols].copy()
            summed_values = group[value_cols].apply(pd.to_numeric, errors="coerce").fillna(0).sum()
            merged_row = pd.concat([base_row, summed_values])
            merged_rows.append(merged_row)

    # åˆå¹¶æ‰€æœ‰ç»“æœ
    merged_df = pd.DataFrame(merged_rows)

    # ä¿è¯åˆ—é¡ºåºä¸åŸå§‹ä¸€è‡´
    return merged_df[summary_df.columns]

def merge_duplicate_rows_by_key(df: pd.DataFrame, field_map: dict, verbose=True) -> pd.DataFrame:
    """
    åˆå¹¶ç»™å®šè¡¨æ ¼ä¸­ 'è§„æ ¼' + 'å“å' + 'æ™¶åœ†å“å' ç›¸åŒçš„è¡Œï¼š
    - æ•°å€¼åˆ—æ±‚å’Œ
    - å…¶ä»–å­—æ®µå–ç¬¬ä¸€è¡Œ
    - ä¸»é”®å­—æ®µæ¥è‡ª field_map

    å¢åŠ  verbose è¾“å‡ºç”¨äºè°ƒè¯•æœªåˆå¹¶æˆåŠŸçš„æƒ…å†µ
    """

    key_cols = [field_map["è§„æ ¼"], field_map["å“å"], field_map["æ™¶åœ†å“å"]]

    for col in key_cols:
        if col not in df.columns:
            raise ValueError(f"ç¼ºå°‘å¿…è¦åˆ—ï¼š{col}")

    # ä¸»é”®åˆ—æ¸…æ´—
    for col in key_cols:
        df[col] = (
            df[col]
            .astype(str)
            .str.strip()
            .str.replace(r"\s+", "", regex=True)
            .str.replace(r"[\u200b\u200e\u200f\n\r]", "", regex=True)
        )

    # è°ƒè¯•è¾“å‡ºé‡å¤ä¸»é”®ç»„åˆ
    dup_keys = df.groupby(key_cols).size().reset_index(name="count")
    dup_keys = dup_keys[dup_keys["count"] > 1]

    if verbose and not dup_keys.empty:
        st.warning(f"âš ï¸ æ£€æµ‹åˆ° {len(dup_keys)} ä¸ªé‡å¤ä¸»é”®ç»„åˆï¼Œå‡†å¤‡åˆå¹¶ï¼š")
        for idx, row in dup_keys.iterrows():
            key_values = tuple(row[col] for col in key_cols)
            st.write(f"ğŸ” ä¸»é”®ç»„ï¼š{key_values}")
            st.dataframe(df[
                (df[key_cols[0]] == key_values[0]) &
                (df[key_cols[1]] == key_values[1]) &
                (df[key_cols[2]] == key_values[2])
            ])

    # æ•°å€¼åˆ—åˆå¹¶
    value_cols = [col for col in df.columns if col not in key_cols and pd.api.types.is_numeric_dtype(df[col])]
    grouped = df.groupby(key_cols, sort=False)
    merged_rows = []

    for keys, group in grouped:
        if len(group) == 1:
            merged_rows.append(group.iloc[0])
        else:
            base_row = group.iloc[0][df.columns.difference(value_cols)].copy()
            summed_values = group[value_cols].apply(pd.to_numeric, errors="coerce").fillna(0).sum()
            merged_row = pd.concat([base_row, summed_values])
            merged_rows.append(merged_row)

    merged_df = pd.DataFrame(merged_rows)

    # ä¿æŒåˆ—é¡ºåºä¸€è‡´
    return merged_df[df.columns]


# ğŸ’¡ è‡ªåŠ¨æŒ‰æ¨¡å—æ’åºæ±‡æ€»åˆ—ï¼šå®‰å…¨åº“å­˜ â†’ æœªäº¤è®¢å• â†’ é¢„æµ‹ â†’ å…¶ä»–
def reorder_summary_columns(df):
    col_list = df.columns.tolist()

    # åŒºåˆ†æ¨¡å—
    safe_cols = [col for col in col_list if "Inv" in col]
    unfulfilled_cols = [col for col in col_list if "æœªäº¤è®¢å•" in col or col == "æ€»æœªäº¤è®¢å•"]
    forecast_cols = [col for col in col_list if "é¢„æµ‹" in col]
    base_cols = ["æ™¶åœ†å“å", "è§„æ ¼", "å“å"]
    other_cols = [col for col in col_list if col not in base_cols + safe_cols + unfulfilled_cols + forecast_cols]

    # ç»„åˆï¼šåŸºç¡€åˆ— + å®‰å…¨åº“å­˜ + æœªäº¤è®¢å• + é¢„æµ‹ + å…¶ä»–
    new_order = base_cols + safe_cols + unfulfilled_cols + forecast_cols + other_cols
    return df[new_order]











def mark_unmatched_keys_on_sheet(ws, unmatched_keys, wafer_col=1, spec_col=2, name_col=3):
    """
    åœ¨ openpyxl å·¥ä½œè¡¨ä¸­æ ‡çº¢æœªåŒ¹é…çš„è¡Œï¼ˆé€šè¿‡ä¸»é”®åŒ¹é…ï¼‰ï¼Œå¯¹ç©ºå€¼/Noneåšæ ‡å‡†åŒ–å¤„ç†ã€‚

    å‚æ•°:
    - ws: openpyxl worksheet å¯¹è±¡
    - unmatched_keys: list of (æ™¶åœ†å“å, è§„æ ¼, å“å) å…ƒç»„
    - wafer_col, spec_col, name_col: è¡¨ç¤ºä¸»é”®åˆ—åœ¨ sheet ä¸­çš„åˆ—å·ï¼ˆä»1å¼€å§‹ï¼‰
    """
    red_fill = PatternFill(start_color="FF9999", end_color="FF9999", fill_type="solid")

    unmatched_set = set(
        tuple(standardize(x) for x in key)
        for key in unmatched_keys
    )

    for row in range(2, ws.max_row + 1):  # ä»ç¬¬2è¡Œå¼€å§‹
        wafer = standardize(ws.cell(row=row, column=wafer_col).value)
        spec = standardize(ws.cell(row=row, column=spec_col).value)
        name = standardize(ws.cell(row=row, column=name_col).value)

        if (wafer, spec, name) in unmatched_set:
            for col in range(1, ws.max_column + 1):
                ws.cell(row=row, column=col).fill = red_fill

def mark_unmatched_keys_on_name(ws, unmatched_keys, name_col=3):
    """
    åœ¨ openpyxl å·¥ä½œè¡¨ä¸­æ ‡çº¢æœªåŒ¹é…çš„å“åè¡Œã€‚

    å‚æ•°:
    - ws: openpyxl worksheet å¯¹è±¡
    - unmatched_keys: list of å“å
    - name_col: å“åæ‰€åœ¨åˆ—ï¼ˆä» 1 å¼€å§‹ï¼‰
    """
    red_fill = PatternFill(start_color="FF9999", end_color="FF9999", fill_type="solid")

    # ç»Ÿä¸€æ ‡å‡†åŒ–æ ¼å¼
    unmatched_set = set(standardize(key) for key in unmatched_keys)

    for row in range(2, ws.max_row + 1):  # ä»ç¬¬2è¡Œå¼€å§‹å¤„ç†
        name = standardize(ws.cell(row=row, column=name_col).value)

        if name in unmatched_set:
            for col in range(1, ws.max_column + 1):
                ws.cell(row=row, column=col).fill = red_fill


def mark_keys_on_sheet(ws, key_set, key_cols=(1, 2, 3)):
    """
    åœ¨å·¥ä½œè¡¨ä¸­æ ‡é»„åŒ¹é… key_set ä¸­çš„è¡Œï¼ŒåŸºäºä¸»é”®åˆ—åŒ¹é…ã€‚

    å‚æ•°:
    - ws: openpyxl worksheet
    - key_set: set of tupleï¼Œä¾‹å¦‚ {("æ™¶åœ†å“å", "è§„æ ¼", "å“å"), ...}
    - key_cols: è¡¨ç¤ºä¸»é”®æ‰€åœ¨çš„åˆ—å· (ä»1å¼€å§‹)ï¼Œé»˜è®¤æ˜¯ (1, 2, 3) å¯¹åº”â€œæ™¶åœ†å“åâ€, â€œè§„æ ¼â€, â€œå“åâ€
    """
    yellow_fill = PatternFill(start_color="FFFF99", end_color="FFFF99", fill_type="solid")

    def standardize(val):
        if val is None:
            return ''
        val = str(val)
        val = val.replace('\u3000', ' ')  # å…¨è§’ç©ºæ ¼
        val = re.sub(r"[\"'â€˜â€™â€œâ€]", '', val)  # å¼•å·
        return val.strip()

    # æ ‡å‡†åŒ–æ‰€æœ‰ key_set ä¸­çš„å€¼
    standardized_keys = set(tuple(standardize(x) for x in key) for key in key_set)

    # st.write(f"ğŸŸ¡ æ ‡é»„åŒ¹é…æ—¥å¿— - Sheet: {ws.title}")

    for row in range(2, ws.max_row + 1):  # ä»ç¬¬2è¡Œå¼€å§‹ï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
        key_raw = [ws.cell(row=row, column=col).value for col in key_cols]
        key = tuple(standardize(v) for v in key_raw)
        display_key = tuple(key_raw)  # ç”¨åŸå§‹å€¼ç”¨äºæ—¥å¿—è¾“å‡º
        # st.write(f"ç¬¬ {row} è¡ŒåŒ¹é…å°è¯•: {display_key}")
        if key in standardized_keys:
            # st.write(f"âœ… ç¬¬ {row} è¡ŒåŒ¹é…æˆåŠŸ: {display_key}")
            for col in range(1, ws.max_column + 1):
                ws.cell(row=row, column=col).fill = yellow_fill
        # else:
            # st.write(f"âŒ ç¬¬ {row} è¡ŒæœªåŒ¹é…: {display_key}")
