import os
import io
import re
import pandas as pd
import streamlit as st
from datetime import datetime, timedelta
from openpyxl.utils import get_column_letter
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.styles import Alignment, Font, PatternFill
from openpyxl import load_workbook
from dateutil.relativedelta import relativedelta
from config import CONFIG
from excel_utils import (
    adjust_column_width,
    clean_df,
    merge_header_for_summary, 
    mark_unmatched_keys_on_sheet,
    mark_keys_on_sheet,
    merge_duplicate_product_names,
    merge_duplicate_rows_by_key,
    clean_key_fields,
    mark_unmatched_keys_on_name,
    reorder_summary_columns,
    clear_nan_cells,
    get_column_index_by_name
)
from mapping_utils import (
    apply_mapping_and_merge, 
    apply_mapping_and_merge_forecast, 
    apply_extended_substitute_mapping
)
from month_selector import process_history_columns
from summary import (
    merge_safety_inventory,
    append_unfulfilled_summary_columns,
    append_forecast_to_summary,
    merge_finished_inventory,
    append_product_in_progress
)
from append_summary import append_forecast_unmatched_to_summary_by_keys
from production_plan import insert_repeated_headers


FIELD_MAPPINGS = {
    "èµ›å“-æœªäº¤è®¢å•": {"è§„æ ¼": "è§„æ ¼", "å“å": "å“å", "æ™¶åœ†å“å": "æ™¶åœ†å“å"},
    "èµ›å“-æˆå“åœ¨åˆ¶": {"è§„æ ¼": "äº§å“è§„æ ¼", "å“å": "äº§å“å“å", "æ™¶åœ†å“å": "æ™¶åœ†å‹å·"},
    "èµ›å“-æˆå“åº“å­˜": {"è§„æ ¼": "è§„æ ¼", "å“å": "å“å", "æ™¶åœ†å“å": "WAFERå“å"},
    "èµ›å“-å®‰å…¨åº“å­˜": {"è§„æ ¼": "OrderInformation", "å“å": "ProductionNO.", "æ™¶åœ†å“å": "WaferID"},
    "èµ›å“-é¢„æµ‹": {"å“å": "ç”Ÿäº§æ–™å·"}
}


class PivotProcessor:
    def process(self, uploaded_files: dict, output_buffer, additional_sheets: dict = None):
        df_finished = pd.DataFrame()
        product_in_progress = pd.DataFrame()
        df_unfulfilled = pd.DataFrame()

        unmatched_safety = []
        unmatched_unfulfilled = []
        unmatched_forecast = []
        unmatched_finished = []
        unmatched_in_progress = []

        key_unfulfilled = []
        key_finished = []
        key_in_progress = []

        mapping_df = additional_sheets.get("èµ›å“-æ–°æ—§æ–™å·", pd.DataFrame())
        
        
        all_mapped_keys = set()

        # æ¸…æ´— additional_sheets ä¸­çš„æ‰€æœ‰ nan å­—ç¬¦ä¸²
        for name in ["èµ›å“-é¢„æµ‹", "èµ›å“-å®‰å…¨åº“å­˜", "èµ›å“-æ–°æ—§æ–™å·"]:
            if name in additional_sheets:
                df = additional_sheets[name]
                df = df.fillna("")  # æ›¿æ¢çœŸæ­£çš„ NaN
                df = df.applymap(lambda x: "" if str(x).strip().lower() == "nan" else str(x).strip() if isinstance(x, str) else x)
                additional_sheets[name] = df  # æ›´æ–°ä¸ºæ¸…æ´—åçš„ df

        # åœ¨ PivotProcessor.process å†…éƒ¨ï¼Œå†™ Excel ä¹‹å‰ï¼š
        # æ£€æŸ¥æ˜¯å¦æœ‰è¡¨å«æœ‰å­—ç¬¦ä¸² "nan"
        for name, df in additional_sheets.items():
            if (df.astype(str).applymap(lambda x: x.lower() == "nan")).any().any():
                st.warning(f"âš ï¸ è¡¨ `{name}` ä¸­å«æœ‰å­—ç¬¦ä¸² 'nan'ï¼Œè¯·ç¡®è®¤æ˜¯å¦æ¸…æ´—å¹²å‡€")



        with pd.ExcelWriter(output_buffer, engine="openpyxl") as writer:
            for filename, file_obj in uploaded_files.items():
                try:
                    df = pd.read_excel(file_obj)
                    df = clean_df(df)
                    config = CONFIG["pivot_config"].get(filename)
                    if not config:
                        st.warning(f"âš ï¸ è·³è¿‡æœªé…ç½®çš„æ–‡ä»¶ï¼š{filename}")
                        continue

                    sheet_name = filename.replace(".xlsx", "")

                    if sheet_name in FIELD_MAPPINGS and not mapping_df.empty:
                        mapping_df.columns = [
                            "æ—§è§„æ ¼", "æ—§å“å", "æ—§æ™¶åœ†å“å",
                            "æ–°è§„æ ¼", "æ–°å“å", "æ–°æ™¶åœ†å“å",
                            "å°è£…å‚", "PC", "åŠæˆå“", "å¤‡æ³¨",
                            "æ›¿ä»£è§„æ ¼1", "æ›¿ä»£å“å1", "æ›¿ä»£æ™¶åœ†1", 
                            "æ›¿ä»£è§„æ ¼2", "æ›¿ä»£å“å2", "æ›¿ä»£æ™¶åœ†2", 
                            "æ›¿ä»£è§„æ ¼3", "æ›¿ä»£å“å3", "æ›¿ä»£æ™¶åœ†3",
                            "æ›¿ä»£è§„æ ¼4", "æ›¿ä»£å“å4", "æ›¿ä»£æ™¶åœ†4"
                        ] + list(mapping_df.columns[22:])
                        st.success(f"âœ… `{sheet_name}` æ­£åœ¨è¿›è¡Œæ–°æ—§æ–™å·æ›¿æ¢...")

                        df, mapped_keys = apply_mapping_and_merge(df, mapping_df, FIELD_MAPPINGS[sheet_name])
                        df, keys_sub = apply_extended_substitute_mapping(df, mapping_df, FIELD_MAPPINGS[sheet_name], None)
                        df = clean_key_fields(df, FIELD_MAPPINGS[sheet_name])
                        df = merge_duplicate_rows_by_key(df, FIELD_MAPPINGS[sheet_name])
                        all_mapped_keys.update(mapped_keys)

                        if sheet_name == "èµ›å“-æœªäº¤è®¢å•":
                            key_unfulfilled = mapped_keys
                        elif sheet_name == "èµ›å“-æˆå“åº“å­˜":
                            key_finished = mapped_keys
                        elif sheet_name == "èµ›å“-æˆå“åœ¨åˆ¶":
                            key_in_progress = mapped_keys

                    if "date_format" in config:
                        df = self._process_date_column(df, config["columns"], config["date_format"])

                    pivoted = self._create_pivot(df, config)
                    pivoted.to_excel(writer, sheet_name=sheet_name, index=False)
                    adjust_column_width(writer, sheet_name, pivoted)

                    if sheet_name == "èµ›å“-æœªäº¤è®¢å•":
                        df_unfulfilled = df
                        pivot_unfulfilled = pivoted
                    elif sheet_name == "èµ›å“-æˆå“åº“å­˜":
                        df_finished = pivoted
                    elif sheet_name == "èµ›å“-æˆå“åœ¨åˆ¶":
                        product_in_progress = pivoted

                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶ `{filename}` å¤„ç†å¤±è´¥: {e}")

            if df_unfulfilled.empty:
                st.error("âŒ ç¼ºå°‘æœªäº¤è®¢å•æ•°æ®ï¼Œæ— æ³•æ„å»ºæ±‡æ€»")
                return

            summary_preview = df_unfulfilled[["æ™¶åœ†å“å", "è§„æ ¼", "å“å"]].drop_duplicates().reset_index(drop=True)
                
            try:
                if "èµ›å“-é¢„æµ‹" in additional_sheets:
                    forecast_df = additional_sheets["èµ›å“-é¢„æµ‹"]
                    forecast_df = clean_df(forecast_df)
                    forecast_df, keys_main = apply_mapping_and_merge_forecast(forecast_df, mapping_df, FIELD_MAPPINGS["èµ›å“-é¢„æµ‹"])
                    ## forecast_df, keys_sub = apply_extended_substitute_mapping(forecast_df, mapping_df, FIELD_MAPPINGS["èµ›å“-é¢„æµ‹"], keys_main)
                    # forecast_df = merge_duplicate_rows_by_key(forecast_df, FIELD_MAPPINGS["èµ›å“-é¢„æµ‹"])
                    # all_mapped_keys.update(keys_main)
                    # all_mapped_keys.update(keys_sub)
                    summary_preview, unmatched_forecast = append_forecast_to_summary(summary_preview, forecast_df)
                    st.success("âœ… å·²åˆå¹¶é¢„æµ‹æ•°æ®")
                    
                    
                    # æ·»åŠ æœªåŒ¹é…çš„é¢„æµ‹é¡¹
                    summary_preview = append_forecast_unmatched_to_summary_by_keys(summary_preview, forecast_df)
                    st.success("âœ… å·²æ·»åŠ æœªåŒ¹é…çš„é¢„æµ‹é¡¹è‡³æ±‡æ€»è¡¨")

                
                if "èµ›å“-å®‰å…¨åº“å­˜" in additional_sheets:
                    df_safety = additional_sheets["èµ›å“-å®‰å…¨åº“å­˜"]
                    df_safety = clean_df(df_safety)
                    df_safety, keys_main = apply_mapping_and_merge(df_safety, mapping_df, FIELD_MAPPINGS["èµ›å“-å®‰å…¨åº“å­˜"])
                    df_safety, keys_sub = apply_extended_substitute_mapping(df_safety, mapping_df, FIELD_MAPPINGS["èµ›å“-å®‰å…¨åº“å­˜"], keys_main)
                    df_safety = merge_duplicate_rows_by_key(df_safety, FIELD_MAPPINGS["èµ›å“-å®‰å…¨åº“å­˜"])
                    # all_mapped_keys.update(keys_main)
                    # all_mapped_keys.update(keys_sub)
                    summary_preview, unmatched_safety = merge_safety_inventory(summary_preview, df_safety)
                    st.success("âœ… å·²åˆå¹¶å®‰å…¨åº“å­˜")
                    
                summary_preview, unmatched_unfulfilled = append_unfulfilled_summary_columns(summary_preview, pivot_unfulfilled)
                st.success("âœ… å·²åˆå¹¶æœªäº¤è®¢å•")
                
                # âœ… æå–æœ€å¤§æœˆä»½å­—æ®µ
                month_pattern = re.compile(r"(\d{4})å¹´(\d{1,2})æœˆ.*æœªäº¤è®¢å•æ•°é‡")
                max_month = None
                
                for col in pivot_unfulfilled.columns:
                    match = month_pattern.match(col)
                    if match:
                        year, month = int(match.group(1)), int(match.group(2))
                        dt = datetime(year, month, 1)
                        if not max_month or dt > max_month:
                            max_month = dt
                
                if max_month:
                    end_date = max_month
                else:
                    end_date = datetime.today() + relativedelta(months=6)  # é»˜è®¤æœªæ¥ 6 ä¸ªæœˆ
                

                if not df_finished.empty:
                    summary_preview, unmatched_finished = merge_finished_inventory(summary_preview, df_finished)
                    st.success("âœ… å·²åˆå¹¶æˆå“åº“å­˜")

                if not product_in_progress.empty:
                    summary_preview, unmatched_in_progress = append_product_in_progress(summary_preview, product_in_progress, mapping_df)
                    st.success("âœ… å·²åˆå¹¶æˆå“åœ¨åˆ¶")


                summary_preview = clean_df(summary_preview)
                summary_preview = summary_preview.drop_duplicates(subset=["æ™¶åœ†å“å", "è§„æ ¼", "å“å"]).reset_index(drop=True)
                summary_preview = merge_duplicate_product_names(summary_preview)
                summary_preview = reorder_summary_columns(summary_preview)


                HEADER_TEMPLATE = [
                    "é”€å”®æ•°é‡", "é”€å”®é‡‘é¢", "æˆå“æŠ•å•è®¡åˆ’", "åŠæˆå“æŠ•å•è®¡åˆ’", "æŠ•å•è®¡åˆ’å‘¨æœŸ",
                    "æˆå“å¯è¡ŒæŠ•å•", "åŠæˆå“å¯è¡ŒæŠ•å•", "æˆå“å®é™…æŠ•å•", "åŠæˆå“å®é™…æŠ•å•",
                    "å›è´§è®¡åˆ’", "å›è´§è®¡åˆ’è°ƒæ•´", "PCå›è´§è®¡åˆ’", "å›è´§å®é™…"
                ]


                # åœ¨ä¿å­˜ summary_preview å‰æ’å…¥ï¼š
                today_month = datetime.today().month
                month_pattern = re.compile(r"(\d{1,2})æœˆé¢„æµ‹")
                forecast_months = []
                
                for col in summary_preview.columns:
                    match = month_pattern.match(str(col))
                    if match:
                        forecast_months.append(int(match.group(1)))

                st.write(forecast_months)
                st.write(len(forecast_months))
                
                # ç¡®å®šæ·»åŠ æœˆä»½èŒƒå›´
                start_month = today_month
                end_month = max(forecast_months) - 1 if forecast_months else start_month

                # âœ… åœ¨ summary_preview ä¸­æ·»åŠ æ¯æœˆå­—æ®µåˆ—ï¼ˆå…¨éƒ¨åˆå§‹åŒ–ä¸ºç©ºæˆ–0ï¼‰
                for m in range(start_month, end_month + 1):
                    for header in HEADER_TEMPLATE:
                        new_col = f"{m}_{header}"
                        summary_preview[new_col] = ""



                def safe_col(df, col):
                    # è¿”å›ç¡®ä¿æ˜¯ float çš„ Seriesï¼Œå­—ç¬¦ä¸²å°†è¢«è½¬ä¸º NaNï¼Œå†ç”¨ 0 æ›¿ä»£
                    return pd.to_numeric(df[col], errors="coerce").fillna(0) if col in df.columns else pd.Series(0, index=df.index)




                df_plan = pd.DataFrame(index=summary_preview.index)

                for idx, month in enumerate(forecast_months[:-1]):  # æœ€åä¸€ä¸ªæœˆä¸ç”Ÿæˆ
                    this_month = f"{month}æœˆ"
                    next_month = f"{forecast_months[idx + 1]}æœˆ"
                    prev_month = f"{forecast_months[idx - 1]}æœˆ" if idx > 0 else None
                
                    # æ„é€ å­—æ®µå
                    col_forecast_this = f"{month}æœˆé¢„æµ‹"
                    col_order_this = f"æœªäº¤è®¢å•æ•°é‡_2025-{month}"
                    col_forecast_next = f"{forecast_months[idx + 1]}æœˆé¢„æµ‹"
                    col_order_next = f"æœªäº¤è®¢å•æ•°é‡_2025-{forecast_months[idx + 1]}"
                    col_target = f"{this_month}_æˆå“æŠ•å•è®¡åˆ’"
                    col_actual_prod = f"{this_month}_æˆå“å®é™…æŠ•å•"
                    col_target_prev = f"{prev_month}_æˆå“æŠ•å•è®¡åˆ’" if prev_month else None
                
                    if idx == 0:
                        # ç¬¬ä¸€ä¸ªæœˆï¼šç‰¹æ®Šç®—æ³•
                        df_plan[col_target] = (
                            safe_col(summary_preview, "InvPart") +
                            pd.DataFrame({
                                "f": safe_col(summary_preview, col_forecast_this),
                                "o": safe_col(summary_preview, col_order_this)
                            }).max(axis=1) +
                            pd.DataFrame({
                                "f": safe_col(summary_preview, col_forecast_next),
                                "o": safe_col(summary_preview, col_order_next)
                            }).max(axis=1) -
                            safe_col(summary_preview, "æ•°é‡_æˆå“ä»“") -
                            safe_col(summary_preview, "æˆå“åœ¨åˆ¶")
                        )
                    else:
                        df_plan[col_target] = (
                            pd.DataFrame({
                                "f": safe_col(summary_preview, col_forecast_next),
                                "o": safe_col(summary_preview, col_order_next)
                            }).max(axis=1) +
                            (safe_col(df_plan, col_target_prev) - safe_col(summary_preview, col_actual_prod))
                        )



                    st.write(df_plan)


                    # âœ… ç¬¬ä¸€æ­¥ï¼šæ‰¾åˆ° summary_preview ä¸­æ‰€æœ‰åŒ…å«â€œæˆå“æŠ•å•è®¡åˆ’â€çš„åˆ—
                    plan_cols_in_summary = [col for col in summary_preview.columns if "æˆå“æŠ•å•è®¡åˆ’" in col]
                    
                    # âœ… ç¬¬äºŒæ­¥ï¼šç¡®ä¿ df_plan åˆ—ä¸ä¹‹æ•°é‡ä¸€è‡´
                    if len(plan_cols_in_summary) != df_plan.shape[1]:
                        st.error(f"âŒ æˆå“æŠ•å•è®¡åˆ’åˆ—æ•°ä¸ä¸€è‡´ï¼šdf_plan æœ‰ {df_plan.shape[1]} åˆ—ï¼Œæ±‡æ€»ä¸­æœ‰ {len(plan_cols_in_summary)} åˆ—")
                    else:
                        # âœ… ç¬¬ä¸‰æ­¥ï¼šæŒ‰é¡ºåºå°† df_plan ä¸­çš„åˆ—å€¼å†™å…¥ summary_preview
                        for i, col in enumerate(plan_cols_in_summary):
                            summary_preview[col] = df_plan.iloc[:, i]
                    
                        st.success("âœ… æˆå“æŠ•å•è®¡åˆ’å·²æˆåŠŸå†™å…¥ summary_preview")




            except Exception as e:
                st.error(f"âŒ æ±‡æ€»æ•°æ®åˆå¹¶å¤±è´¥: {e}")
                return

            summary_preview.to_excel(writer, sheet_name="æ±‡æ€»", index=False)
            adjust_column_width(writer, "æ±‡æ€»", summary_preview)


            ws = writer.sheets["æ±‡æ€»"]





            header_row = list(summary_preview.columns)
            unfulfilled_cols = [col for col in header_row if "æœªäº¤è®¢å•æ•°é‡" in col or col in ("æ€»æœªäº¤è®¢å•", "å†å²æœªäº¤è®¢å•æ•°é‡")]
            forecast_cols = [col for col in header_row if "é¢„æµ‹" in col]
            finished_cols = [col for col in header_row if col in ("æ•°é‡_HOLDä»“", "æ•°é‡_æˆå“ä»“", "æ•°é‡_åŠæˆå“ä»“")]

            merge_header_for_summary(
                ws, summary_preview,
                {
                    "å®‰å…¨åº“å­˜": (" InvWaf", " InvPart"),
                    "æœªäº¤è®¢å•": (unfulfilled_cols[0], unfulfilled_cols[-1]),
                    "é¢„æµ‹": (forecast_cols[0], forecast_cols[-1]) if forecast_cols else ("", ""),
                    "æˆå“åº“å­˜": (finished_cols[0], finished_cols[-1]) if finished_cols else ("", ""),
                    "æˆå“åœ¨åˆ¶": ("æˆå“åœ¨åˆ¶", "åŠæˆå“åœ¨åˆ¶")
                }
            )

            for key, df in additional_sheets.items():
                df.to_excel(writer, sheet_name=key, index=False)
                adjust_column_width(writer, key, df)

            # æ¯ä¸ª sheet ä¸­ç”¨äºæ ‡è®°çš„å­—æ®µåï¼ˆç›®æ ‡åˆ—ï¼‰åŠè¡¨å¤´æ‰€åœ¨è¡Œï¼ˆä» 1 å¼€å§‹ï¼‰
            sheet_field_config = {
                "èµ›å“-å®‰å…¨åº“å­˜": {"field_name": "ProductionNO.", "header_row": 1},
                "èµ›å“-æœªäº¤è®¢å•": {"field_name": "å“å", "header_row": 1},
                "èµ›å“-é¢„æµ‹": {"field_name": "ç”Ÿäº§æ–™å·", "header_row": 1},
                "æ±‡æ€»": {"field_name": "å“å", "header_row": 2},  # æ±‡æ€»è¡¨é€šå¸¸ä»ç¬¬2è¡Œèµ·æ‰æ˜¯å­—æ®µè¡Œ
                "èµ›å“-æˆå“åº“å­˜": {"field_name": "å“å", "header_row": 1},
                "èµ›å“-æˆå“åœ¨åˆ¶": {"field_name": "äº§å“å“å", "header_row": 1},
            }

            sheet_key_mapping = {
                    "èµ›å“-å®‰å…¨åº“å­˜": unmatched_safety,
                    "èµ›å“-æœªäº¤è®¢å•": unmatched_unfulfilled,
                    "èµ›å“-é¢„æµ‹": unmatched_forecast,
                    "èµ›å“-æˆå“åº“å­˜": unmatched_finished,
                    "èµ›å“-æˆå“åœ¨åˆ¶": unmatched_in_progress,
                }
                

            try:
                # æ ‡çº¢æœªåŒ¹é…è¡Œ
                for sheet_name, unmatched_keys in sheet_key_mapping.items():
                    if sheet_name in writer.sheets and sheet_name in sheet_field_config:
                        ws = writer.sheets[sheet_name]
                        config = sheet_field_config[sheet_name]
                        field_name = config["field_name"]
                        header_row = config["header_row"]
                        col_idx = get_column_index_by_name(ws, field_name, header_row)
                
                        if col_idx:
                            mark_unmatched_keys_on_name(ws, unmatched_keys, name_col=col_idx)
                        else:
                            st.warning(f"âš ï¸ `{sheet_name}` ä¸­æœªæ‰¾åˆ°å­—æ®µ `{field_name}`ï¼Œè·³è¿‡æœªåŒ¹é…æ ‡è®°")

                mark_unmatched_keys_on_name(writer.sheets["æ±‡æ€»"], unmatched_forecast, name_col=3)


                """
                æ ‡é»„
                mark_keys_on_sheet(writer.sheets["æ±‡æ€»"], all_mapped_keys, (2, 3, 1))
                mark_keys_on_sheet(writer.sheets["èµ›å“-å®‰å…¨åº“å­˜"], all_mapped_keys, (3, 5, 1))
                mark_keys_on_sheet(writer.sheets["èµ›å“-æœªäº¤è®¢å•"], all_mapped_keys, (2, 3, 1))
                mark_keys_on_sheet(writer.sheets["èµ›å“-é¢„æµ‹"], all_mapped_keys, (1, 2, 3))
                mark_keys_on_sheet(writer.sheets["èµ›å“-æˆå“åº“å­˜"], all_mapped_keys, (2, 3, 1))
                mark_keys_on_sheet(writer.sheets["èµ›å“-æˆå“åœ¨åˆ¶"], all_mapped_keys, (4, 5, 3))
                """

                st.success("âœ… å·²å®ŒæˆæœªåŒ¹é…é¡¹æ ‡è®°")
            except Exception as e:
                st.warning(f"âš ï¸ æœªåŒ¹é…æ ‡è®°å¤±è´¥ï¼š{e}")



        # âœ… æ›¿æ¢è¿™äº›æŒ‡å®šè¡¨çš„ nan å€¼ä¸ºç©º
        for sheet_name in ["èµ›å“-å®‰å…¨åº“å­˜", "èµ›å“-é¢„æµ‹", "èµ›å“-æ–°æ—§æ–™å·", "æ±‡æ€»"]:
            if sheet_name in writer.sheets:
                clear_nan_cells(writer.sheets[sheet_name])


            output_buffer.seek(0)
        


    def _process_date_column(self, df, date_col, date_format):
        if pd.api.types.is_numeric_dtype(df[date_col]):
            df[date_col] = df[date_col].apply(self._excel_serial_to_date)
        else:
            df[date_col] = pd.to_datetime(df[date_col], errors="coerce")

        new_col = f"{date_col}_å¹´æœˆ"
        df[new_col] = df[date_col].dt.strftime(date_format)
        df[new_col] = df[new_col].fillna("æœªçŸ¥æ—¥æœŸ")
        return df

    def _excel_serial_to_date(self, serial):
        try:
            return datetime(1899, 12, 30) + timedelta(days=float(serial))
        except:
            return pd.NaT

    def _create_pivot(self, df, config):
        config = config.copy()
        if "date_format" in config:
            config["columns"] = f"{config['columns']}_å¹´æœˆ"

        pivoted = pd.pivot_table(
            df,
            index=config["index"],
            columns=config["columns"],
            values=config["values"],
            aggfunc=config["aggfunc"],
            fill_value=0
        )

        pivoted.columns = [f"{col[0]}_{col[1]}" if isinstance(col, tuple) else str(col) for col in pivoted.columns]

        if pd.Series(pivoted.columns).duplicated().any():
            from pandas.io.parsers import ParserBase
            original_cols = pivoted.columns
            deduped_cols = ParserBase({'names': original_cols})._maybe_dedup_names(original_cols)
            pivoted.columns = deduped_cols

        pivoted = pivoted.reset_index()

        if CONFIG.get("selected_month") and config.get("values") and "æœªäº¤è®¢å•æ•°é‡" in config.get("values"):
            st.info(f"ğŸ“… åˆå¹¶å†å²æ•°æ®è‡³ï¼š{CONFIG['selected_month']}")
            pivoted = process_history_columns(pivoted, config, CONFIG["selected_month"])
        return pivoted
