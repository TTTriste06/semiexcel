import pandas as pd
import streamlit as st


def apply_mapping_and_merge(df, mapping_df, field_map, verbose=True):
    spec_col = field_map["è§„æ ¼"]
    name_col = field_map["å“å"]
    wafer_col = field_map["æ™¶åœ†å“å"]

    for col in [spec_col, name_col, wafer_col]:
        df[col] = df[col].astype(str).str.strip()
    for col in ["æ—§è§„æ ¼", "æ—§å“å", "æ—§æ™¶åœ†å“å"]:
        mapping_df[col] = mapping_df[col].astype(str).str.strip()

    left_on = [spec_col, name_col, wafer_col]
    right_on = ["æ—§è§„æ ¼", "æ—§å“å", "æ—§æ™¶åœ†å“å"]

    try:
        df_merged = df.merge(mapping_df, how="left", left_on=left_on, right_on=right_on)

        matched = df_merged["æ–°è§„æ ¼"].notna()
        unmatched_count = (~matched).sum()

        # ç”Ÿæˆå¸ƒå°”æ©ç ï¼šæˆåŠŸè¢«æ–°æ—§æ–™å·æ›¿æ¢çš„è¡Œ
        mask_None = (
            df_merged["æ–°è§„æ ¼"].notna() & (df_merged["æ–°è§„æ ¼"].astype(str).str.strip() != "") &
            df_merged["æ–°å“å"].notna() & (df_merged["æ–°å“å"].astype(str).str.strip() != "") &
            df_merged["æ–°æ™¶åœ†å“å"].notna() & (df_merged["æ–°æ™¶åœ†å“å"].astype(str).str.strip() != "")
        )

        df_merged["_ç”±æ–°æ—§æ–™å·æ˜ å°„"] = mask_None  # æ ‡è®°åˆ— âœ…

        # æ›¿æ¢å­—æ®µ
        df_merged.loc[mask_None, spec_col] = df_merged.loc[mask_None, "æ–°è§„æ ¼"]
        df_merged.loc[mask_None, name_col] = df_merged.loc[mask_None, "æ–°å“å"]
        df_merged.loc[mask_None, wafer_col] = df_merged.loc[mask_None, "æ–°æ™¶åœ†å“å"]

        # åˆ é™¤ä¸­é—´åˆ—
        drop_cols = ["æ—§è§„æ ¼", "æ—§å“å", "æ—§æ™¶åœ†å“å", "æ–°è§„æ ¼", "æ–°å“å", "æ–°æ™¶åœ†å“å"]
        df_cleaned = df_merged.drop(columns=[col for col in drop_cols if col in df_merged.columns])

        group_cols = [spec_col, name_col, wafer_col]
        numeric_cols = df_cleaned.select_dtypes(include="number").columns.tolist()
        sum_cols = [col for col in numeric_cols if col not in group_cols]

        df_grouped = df_cleaned.groupby(group_cols, as_index=False)[sum_cols].sum()

        other_cols = [col for col in df_cleaned.columns if col not in group_cols + sum_cols]
        if other_cols:
            df_first = df_cleaned.groupby(group_cols, as_index=False)[other_cols].first()
            df_grouped = pd.merge(df_grouped, df_first, on=group_cols, how="left")

        # âœ… è¿”å›ä¸»é”®é›†åˆ
        mapped_keys = set(
            tuple(df_merged.loc[idx, [spec_col, name_col, wafer_col]].values)
            for idx in df_merged.index[df_merged["_ç”±æ–°æ—§æ–™å·æ˜ å°„"]]
        )

        return df_grouped, mapped_keys

    except Exception as e:
        print(f"âŒ æ›¿æ¢å¤±è´¥: {e}")
        return df, set()


def apply_mapping_and_merge_forecast(df, mapping_df, field_map, verbose=True):
    name_col = field_map["å“å"]

    # æ¸…æ´—å­—æ®µ
    # df[name_col] = df[name_col].astype(str).str.strip()
    mapping_df["æ—§å“å"] = mapping_df["æ—§å“å"].astype(str).str.strip()
    mapping_df["æ–°å“å"] = mapping_df["æ–°å“å"].astype(str).str.strip()

    # åˆå¹¶ï¼ˆä»…æŒ‰å“åï¼‰
    try:
        df_merged = df.merge(mapping_df[["æ—§å“å", "æ–°å“å"]], how="left", left_on=[name_col], right_on=["æ—§å“å"])

        # æˆåŠŸæ›¿æ¢çš„æ ‡å¿—
        mask_replace = df_merged["æ–°å“å"].notna() & (df_merged["æ–°å“å"].str.strip() != "")

        if verbose:
            st.write(f"âœ… æ›¿æ¢æˆåŠŸè¡Œæ•°: {mask_replace.sum()}")
            st.write(f"âš ï¸ æœªåŒ¹é…è¡Œæ•°: {(~mask_replace).sum()}")

        df_merged["_ç”±æ–°æ—§æ–™å·æ˜ å°„"] = mask_replace

        # æ›¿æ¢å“å
        df_merged.loc[mask_replace, name_col] = df_merged.loc[mask_replace, "æ–°å“å"]

        # åˆ é™¤ä¸­é—´åˆ—
        df_cleaned = df_merged.drop(columns=[col for col in ["æ—§å“å", "æ–°å“å"] if col in df_merged.columns])

        # èšåˆå­—æ®µ
        group_cols = [name_col]
        numeric_cols = df_cleaned.select_dtypes(include="number").columns.tolist()
        sum_cols = [col for col in numeric_cols if col not in group_cols]

        df_grouped = df_cleaned.groupby(group_cols, as_index=False)[sum_cols].sum()

        # ä¿ç•™å…¶ä»–éæ•°å€¼å­—æ®µ
        other_cols = [col for col in df_cleaned.columns if col not in group_cols + sum_cols]
        if other_cols:
            df_first = df_cleaned.groupby(group_cols, as_index=False)[other_cols].first()
            df_grouped = pd.merge(df_grouped, df_first, on=group_cols, how="left")

        # è¿”å›æ˜ å°„é”®
        mapped_keys = set(
            tuple(df_merged.loc[idx, [name_col]].values)
            for idx in df_merged.index[df_merged["_ç”±æ–°æ—§æ–™å·æ˜ å°„"]]
        )

        return df_grouped, mapped_keys

    except Exception as e:
        st.error(f"âŒ æ›¿æ¢å¤±è´¥: {e}")
        return df, set()


# æˆ‘ä»¬é‡æ–°å†™ä¸€ä¸‹apply_extended_substitute_mappingï¼Œé¦–å…ˆæ‰¾åˆ°K-Våˆ—ä¸ä¸ºç©ºçš„æ‰€æœ‰è¡Œï¼Œåªç”¨ä¿ç•™æ–°è§„æ ¼ï¼Œæ–°å“åï¼Œæ–°æ™¶åœ†å“åï¼Œå’Œå››ç»„æ›¿ä»£æ–™å·ï¼ˆæ›¿ä»£è§„æ ¼, æ›¿ä»£å“å, æ›¿ä»£æ™¶åœ†ï¼‰ï¼Œ
# å¦‚æœè¿™ç»„æ›¿ä»£æ–™å·ä¸ä¸ºç©ºï¼Œå°±åœ¨éœ€è¦åˆå¹¶çš„sheetä¸­æ‰¾åˆ°å¯¹åº”ä¿¡æ¯çš„è¡Œï¼Œæ›¿æ¢æ›¿ä»£è§„æ ¼, æ›¿ä»£å“å, æ›¿ä»£æ™¶åœ†ä¸ºæ–°è§„æ ¼ï¼Œæ–°å“åï¼Œæ–°æ™¶åœ†å“åï¼Œå¹¶ä¸ä¹‹å‰çš„æ–°è§„æ ¼ï¼Œæ–°å“åï¼Œæ–°æ™¶åœ†å“åè¡Œåˆå¹¶

# åœ¨åˆå¹¶ä¸¤è¡Œçš„æ—¶å€™ï¼Œåªè¦è¿™ä¸ªsheetä¸­å¯¹åº”çš„è§„æ ¼ï¼Œå“åï¼Œæ™¶åœ†å“åæ˜¯ä¸€æ ·çš„ï¼ˆæ¯ä¸ªsheetå¯¹åº”çš„åå­—ä¸ä¸€æ ·ï¼ŒFIELD_MAPPINGSæœ‰å¯¹ç…§çš„ï¼‰ï¼Œå°±éœ€è¦åˆå¹¶è¿™ä¸¤è¡Œï¼Œå¦‚æœåˆ«çš„éæ•°å­—ä¿¡æ¯ä¸ä¸€è‡´ï¼Œå°±å–ä¸æ˜¯æ›¿æ¢æ–™å·é‚£ä¸€è¡Œçš„ä¿¡æ¯

def apply_extended_substitute_mapping(df, mapping_df, field_map, verbose=True):
    spec_col = field_map["è§„æ ¼"]
    name_col = field_map["å“å"]
    wafer_col = field_map["æ™¶åœ†å“å"]

    # æ¸…æ´—ä¸»å­—æ®µ
    for col in [spec_col, name_col, wafer_col]:
        df[col] = df[col].astype(str).str.strip().str.replace("\n", "").str.replace("\r", "")

    substitute_records = []

    for i in range(1, 5):
        sub_spec = f"æ›¿ä»£è§„æ ¼{i}"
        sub_name = f"æ›¿ä»£å“å{i}"
        sub_wafer = f"æ›¿ä»£æ™¶åœ†{i}"

        for col in [sub_spec, sub_name, sub_wafer, "æ–°è§„æ ¼", "æ–°å“å", "æ–°æ™¶åœ†å“å"]:
            if col not in mapping_df.columns:
                mapping_df[col] = ""
            mapping_df[col] = mapping_df[col].astype(str).str.strip().str.replace("\n", "").str.replace("\r", "")

        filtered = mapping_df[
            mapping_df[[sub_spec, sub_name, sub_wafer, "æ–°è§„æ ¼", "æ–°å“å", "æ–°æ™¶åœ†å“å"]].notna().all(axis=1)
        ]

        for _, row in filtered.iterrows():
            substitute_records.append({
                "æ—§è§„æ ¼": row[sub_spec],
                "æ—§å“å": row[sub_name],
                "æ—§æ™¶åœ†å“å": row[sub_wafer],
                "æ–°è§„æ ¼": row["æ–°è§„æ ¼"],
                "æ–°å“å": row["æ–°å“å"],
                "æ–°æ™¶åœ†å“å": row["æ–°æ™¶åœ†å“å"]
            })

    # æ‰§è¡Œæ›¿æ¢ï¼ˆä¸è¿›è¡Œåˆå¹¶ï¼‰
    matched_keys = set()
    for sub in substitute_records:
        mask = (
            (df[spec_col] == sub["æ—§è§„æ ¼"]) &
            (df[name_col] == sub["æ—§å“å"]) &
            (df[wafer_col] == sub["æ—§æ™¶åœ†å“å"])
        )
        if mask.any():
            if verbose:
                st.write(
                    f"ğŸ” æ›¿æ¢: ({sub['æ—§è§„æ ¼']}, {sub['æ—§å“å']}, {sub['æ—§æ™¶åœ†å“å']}) â†’ "
                    f"({sub['æ–°è§„æ ¼']}, {sub['æ–°å“å']}, {sub['æ–°æ™¶åœ†å“å']})ï¼Œæ›¿æ¢è¡Œæ•°: {mask.sum()}"
                )
            df.loc[mask, spec_col] = sub["æ–°è§„æ ¼"]
            df.loc[mask, name_col] = sub["æ–°å“å"]
            df.loc[mask, wafer_col] = sub["æ–°æ™¶åœ†å“å"]
            matched_keys.update(
                tuple(x) for x in df.loc[mask, [spec_col, name_col, wafer_col]].values
            )

    if verbose:
        st.success(f"âœ… æ›¿ä»£æ–™å·æ›¿æ¢æˆåŠŸæ•°: {len(matched_keys)}")

    return df, matched_keys
